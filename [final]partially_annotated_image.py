# -*- coding: utf-8 -*-
"""[FINAL]Partially_annotated_image.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PoAQi_Lv8lVBFtQfkYk0qGJKCOHqHQQY

**CODE as per PEP8 Guidelines**
"""

import cv2
import numpy as np
from matplotlib import pyplot as plt


def should_expand(ref_array, new_array, tolerance=30, match_threshold=0.1):
    """Checking whether the expansion on a particular side should occur or not."""
    abs_diff = np.abs(new_array.astype(int) - ref_array.astype(int))
    matches = abs_diff <= tolerance
    match_percentage = np.mean(matches)
    return match_percentage >= match_threshold


def dynamic_expand_box(image, box, max_expansion=250):
    """Dynamically expanding the bounding box."""
    x, y, w, h = box
    rows, cols = image.shape[:2]

    expand_top, expand_left, expand_right = 0, 0, 0
    expand_bottom = rows - (y + h)

    for side in ['top', 'left', 'right']:
        for expansion in range(1, max_expansion):
            if side == 'top' and y - expansion >= 0:
                ref_array = image[y:y + 1, x:x + w]
                new_array = image[y - expansion:y - expansion + 1, x:x + w]
            elif side == 'left' and x - expansion >= 0:
                ref_array = image[y:y + h, x:x + 1]
                new_array = image[y:y + h, x - expansion:x - expansion + 1]
            elif side == 'right' and x + w + expansion <= cols:
                ref_array = image[y:y + h, x + w - 1:x + w]
                new_array = image[y:y + h, x + w + expansion - 1:x + w + expansion]
            else:
                continue

            if should_expand(ref_array, new_array):
                if side == 'top':
                    expand_top += 1
                elif side == 'left':
                    expand_left += 1
                elif side == 'right':
                    expand_right += 1
            else:
                break

    new_x = x - expand_left
    new_y = y - expand_top
    new_w = w + expand_left + expand_right
    new_h = h + expand_top + expand_bottom

    return new_x, new_y, new_w, new_h


def process_images(original_image_path, fully_annotated_image_path):
    """creating partially annotated image."""
    original_image = cv2.imread(original_image_path)
    fully_annotated_image = cv2.imread(fully_annotated_image_path)

    max_height = max(original_image.shape[0], fully_annotated_image.shape[0])
    max_width = max(original_image.shape[1], fully_annotated_image.shape[1])

    original_image_resized = cv2.resize(original_image, (max_width, max_height))
    fully_annotated_image_resized = cv2.resize(fully_annotated_image, (max_width, max_height))

    gray_image = cv2.cvtColor(original_image_resized, cv2.COLOR_BGR2GRAY)
    cat_face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalcatface_extended.xml')

    for i in range(1, 30):
        cat_faces = cat_face_cascade.detectMultiScale(
            gray_image, scaleFactor=1.1, minNeighbors=i, minSize=(75, 75))
        if cat_faces.shape[0] == 1:
            break

    expanded_boxes = [dynamic_expand_box(gray_image, box) for box in cat_faces]

    mask = np.zeros_like(gray_image, dtype=np.uint8)
    for x, y, w, h in expanded_boxes:
        mask[y:y + h, x:x + w] = 1

    partially_annotated_image = np.where(
        mask[:, :, np.newaxis], fully_annotated_image_resized, original_image_resized)

    partially_annotated_image_rgb = cv2.cvtColor(partially_annotated_image, cv2.COLOR_BGR2RGB)
    plt.imshow(partially_annotated_image_rgb)
    plt.axis('off')
    plt.show()

    return partially_annotated_image


def get_output_image(original_image_path, fully_annotated_image_path, partially_annotated_image_path):
    """Writing the processed image to the given path as asked in the assignment."""
    if isinstance(original_image_path, list) and isinstance(fully_annotated_image_path, list) \
            and isinstance(partially_annotated_image_path, list):
        if len(original_image_path) != len(fully_annotated_image_path) \
                or len(original_image_path) != len(partially_annotated_image_path):
            raise ValueError("Exception: List arguments must be of the same length")

        for o_path, f_path, p_path in zip(
                original_image_path, fully_annotated_image_path, partially_annotated_image_path):
            processed_image = process_images(o_path, f_path)
            cv2.imwrite(p_path, processed_image)
    elif isinstance(original_image_path, str) and isinstance(fully_annotated_image_path, str) \
            and isinstance(partially_annotated_image_path, str):
        processed_image = process_images(original_image_path, fully_annotated_image_path)
        cv2.imwrite(partially_annotated_image_path, processed_image)
    else:
        raise ValueError("Exception: All arguments must be of the same type (either all strings or all lists)")


# Paths
original_image_path = '/content/Akaike_Data_CV/img3/original_image.jpg'
fully_annotated_image_path = '/content/Akaike_Data_CV/img3/fully_annotated_image.jpg'
partially_annotated_image_path = '/content/Akaike_Data_CV/img3/partially_annotated_image.jpg'

# Usage
get_output_image(original_image_path, fully_annotated_image_path, partially_annotated_image_path)

# For lists
original_image_path_list = [f"/content/Akaike_Data_CV/img{i}/original_image.jpg" for i in range(1, 10)]
fully_annotated_image_path_list = [f"/content/Akaike_Data_CV/img{i}/fully_annotated_image.jpg" for i in range(1, 10)]
partially_annotated_image_path_list = [f"/content/Akaike_Data_CV/img{i}/partially_annotated_image.jpg" for i in range(1, 10)]

get_output_image(
    original_image_path_list,
    fully_annotated_image_path_list,
    partially_annotated_image_path_list)

!zip -r /content/akaikeResult.zip /content/Akaike_Data_CV

from google.colab import files
files.download("/content/akaikeResult.zip")